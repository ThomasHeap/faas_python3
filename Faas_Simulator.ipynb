{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference on Faas Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are going to import basic packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATH\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# VISUALIZATION\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sbi\n",
    "import sbi\n",
    "import sbi.utils as utils\n",
    "from sbi.inference.snpe.snpe_c import SnpeC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove top and right axis from plots\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different required components\n",
    "\n",
    "Before running inference, let us define the different required components:\n",
    "\n",
    "1. observed data\n",
    "2. simulator\n",
    "4. prior over model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faas_helper_fns import simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting the input current and the simulator together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_faas_model(params):\n",
    "    \n",
    "    #params = np.asarray(params)\n",
    "    \n",
    "    states = simulator(th=params)\n",
    "    t = np.genfromtxt('data/time_points.csv', delimiter=',')\n",
    "    \n",
    "    return {'data': states,\n",
    "            'time': t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# three sets of (g_Na, g_K)\n",
    "theta_1 = [8.886491e+00,  7.924279e+00]\n",
    "#   1.050515e+01]#  7.397940e+00]# -3.682371e+00, -4.509306e+00, -6.162727e+00,\n",
    "#  -6.585027e+00,  1.100000e-03, -3.900000e-01] \n",
    "\n",
    "theta_2 = [8.886491e+00,  7.924279e+00,\n",
    "   1.050515e+01,  7.397940e+00, -3.682371e+00, -4.509306e+00, -6.162727e+00,\n",
    "  -6.585027e+00,  1.100000e-03, -3.900000e-01] \n",
    "\n",
    "\n",
    "params = torch.FloatTensor([theta_1,theta_1])\n",
    "\n",
    "t = np.genfromtxt('data/time_points.csv', delimiter=',')\n",
    "                  \n",
    "num_samples = len(params[:,0])\n",
    "sim_samples = np.zeros((num_samples, 94 ,259))\n",
    "\n",
    "\n",
    "sim_samples[:num_samples,:,:] = run_faas_model(params)['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# colors for traces\n",
    "col_min = 2\n",
    "num_colors = num_samples+col_min\n",
    "cm1 = mpl.cm.Blues\n",
    "col1 = [cm1(1.*i/num_colors) for i in range(col_min,num_colors)]\n",
    "\n",
    "# plotting\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for j in np.arange(92//4):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "    for i in range(num_samples):\n",
    "        ax1.plot(t,sim_samples[i,j*4,:],color=col1[i],lw=2, label = str(i))\n",
    "        ax1.set_title(str(j*4+1))\n",
    "        ax2.plot(t,sim_samples[i,j*4+1,:],color=col1[i],lw=2, label = str(i))\n",
    "        ax2.set_title(str(j*4+2))\n",
    "        ax3.plot(t,sim_samples[i,j*4+2,:],color=col1[i],lw=2, label = str(i))\n",
    "        ax3.set_title(str(j*4+3))\n",
    "        ax4.plot(t,sim_samples[i,j*4+3,:],color=col1[i],lw=2, label = str(i))\n",
    "        ax4.set_title(str(j*4+4))\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    fig.tight_layout()\n",
    "    \n",
    "plt.figure(figsize=(20,10))\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)        \n",
    "for i in range(num_samples):\n",
    "    ax1.plot(t,sim_samples[i,92,:],color=col1[i],lw=2, label = str(i))\n",
    "    ax1.set_title(str(93))\n",
    "    ax2.plot(t,sim_samples[i,93,:],color=col1[i],lw=2, label = str(i))\n",
    "    ax2.set_title(str(94))\n",
    "plt.ylabel('voltage (mV)')\n",
    "plt.legend(loc=\"upper right\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "#fig.set_xticks([])\n",
    "#fig.set_yticks([-80, -20, 40])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the voltage traces can be quite diverse for different parameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, we are not interested in matching the exact trace, but only in matching certain features thereof. In this example of the Hodgkin Huxley model, the summary features are the number of spikes, the mean resting potential, the standard deviation of the resting potential, and the first 4 voltage moments, mean, standard deviation, skewness and kurtosis. In the function `calculate_summary_statistics()` below, we compute these statistics from the output of the Hodgkin Huxley simulator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faas_helper_fns import calc_summ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we define a function that performs all of the above steps at once. The function `simulation_wrapper` takes in conductance values, runs the Hodgkin Huxley model and then returns the summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_wrapper(params):\n",
    "    \"\"\"\n",
    "    Takes in conductance values and then first runs the Hodgkin Huxley model and then returns the summary statistics as torch.Tensor\n",
    "    \"\"\"\n",
    "    obs = run_faas_model(params)\n",
    "\n",
    "    \n",
    "    obs['data'] = [i + np.random.normal(scale=0.01, size=i.shape) for i in obs['data']]\n",
    "    \n",
    "    summstats = np.asarray(calc_summ(d=obs))\n",
    "    return summstats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sbi` takes any function as simulator. Thus, `sbi` also has the flexibility to use simulators that utilize external packages, e.g., Brian (http://briansimulator.org/), nest (https://www.nest-simulator.org/), or NEURON (https://neuron.yale.edu/neuron/). External simulators do not even need to be Python-based as long as they store simulation outputs in a format that can be read from Python. All that is necessary is to wrap your external simulator of choice into a python callable that takes a parameter set and outputs a set of summary statistics we want to fit the parameters to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors for traces\n",
    "col_min = 2\n",
    "num_colors = num_samples+col_min\n",
    "cm1 = mpl.cm.Blues\n",
    "col1 = [cm1(1.*i/num_colors) for i in range(col_min,num_colors)]\n",
    "\n",
    "# plotting\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for j in np.arange(1):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "    for i in range(num_samples):\n",
    "        ax1.plot(t,sim_samples[i,j*4,:] + np.random.normal(scale=0.01, size=259),color=col1[i],lw=2, label = str(i))\n",
    "        ax1.set_title(str(j*4+1))\n",
    "        ax2.plot(t,sim_samples[i,j*4+1,:] + np.random.normal(scale=0.01, size=259),color=col1[i],lw=2, label = str(i))\n",
    "        ax2.set_title(str(j*4+2))\n",
    "        ax3.plot(t,sim_samples[i,j*4+2,:] + np.random.normal(scale=0.01, size=259),color=col1[i],lw=2, label = str(i))\n",
    "        ax3.set_title(str(j*4+3))\n",
    "        ax4.plot(t,sim_samples[i,j*4+3,:] + np.random.normal(scale=0.01, size=259),color=col1[i],lw=2, label = str(i))\n",
    "        ax4.set_title(str(j*4+4))\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    fig.tight_layout()\n",
    "    \n",
    "for i in range(num_samples):\n",
    "    print(simulation_wrapper(params=params[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Prior over model parameters\n",
    "\n",
    "Now that we have the simulator, we need to define a function with the prior over the model parameters ($\\bar g_{Na}$,$\\bar g_K$), which in this case is chosen to be a Uniform distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_max = np.array([12e+00, 10])# 12])# -3, -4, -4,-4] + [0.05,0.5])\n",
    "prior_min = np.array([4e+00,  2])# 4])# -10, -10, -10, -12] + [-0.05,-0.5])\n",
    "prior = utils.torchutils.BoxUniform(low=torch.as_tensor(prior_min), high=torch.as_tensor(prior_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coming back to the observed data\n",
    "As mentioned at the beginning of the tutorial, the observed data are generated by the Hodgkin-Huxley model with a set of known parameters ($\\bar g_{Na}$,$\\bar g_K$). To illustrate how to compute the summary statistics of the observed data, let us regenerate the observed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true parameters and respective labels\n",
    "true_params = np.array([8.886491e+00,  7.924279e+00])\n",
    "#   1.050515e+01])# -3.682371e+00, -4.509306e+00, -6.162727e+00,\n",
    "#  -6.585027e+00,  1.100000e-03, -3.900000e-01])       \n",
    "labels_params = ['KonTN', 'KonTC']# 'KonRN', 'KonRC']# 'KDTN', 'KDTC', 'KDRN', 'KDRC', 'malpha', 'alpha0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_trace = run_faas_model(torch.FloatTensor([true_params]))\n",
    "observation_summary_statistics = torch.as_tensor(calc_summ(observation_trace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(observation_summary_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we had already shown above, the observed voltage traces look as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "t = observation_trace['time']\n",
    "num_samples = 1\n",
    "for j in np.arange(92//4):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "    ax1.plot(t,observation_trace['data'][0][j*4,:],lw=2)\n",
    "    ax1.set_title(str(j*4+1))\n",
    "    ax2.plot(t,observation_trace['data'][0][j*4+1,:],lw=2)\n",
    "    ax2.set_title(str(j*4+2))\n",
    "    ax3.plot(t,observation_trace['data'][0][j*4+2,:],lw=2)\n",
    "    ax3.set_title(str(j*4+3))\n",
    "    ax4.plot(t,observation_trace['data'][0][j*4+3,:],lw=2)\n",
    "    ax4.set_title(str(j*4+4))\n",
    "    fig.tight_layout()\n",
    "    \n",
    "plt.figure(figsize=(20,10))\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)        \n",
    "\n",
    "ax1.plot(t,observation_trace['data'][0][92,:],lw=2)\n",
    "ax1.set_title(str(93))\n",
    "ax2.plot(t,observation_trace['data'][0][93,:],lw=2)\n",
    "ax2.set_title(str(94))\n",
    "plt.ylabel('voltage (mV)')\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "Now that we have all the required components, we can run inference with SNPE. We start by importing our SNPE object of choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to use SNPE to identify parameters whose activity matches this trace. To do so, we instantiate the SNPE object..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "snpe_common_args = dict(\n",
    "    simulator=simulation_wrapper,\n",
    "    x_o=observation_summary_statistics,\n",
    "    prior=prior,\n",
    "    simulation_batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and run the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0410d6fc8ecd487a9d53e1201e87e81c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[ 8.4386,  4.0089, 10.2334,  9.1387],\n",
      "        [11.9538,  4.9267,  7.1830,  6.5872],\n",
      "        [ 8.9992,  9.9438,  4.3063,  7.2950],\n",
      "        [ 7.7127,  6.3695, 11.6498,  6.2321],\n",
      "        [ 6.1897,  8.8245,  9.1109,  7.4258],\n",
      "        [ 8.7118,  4.7106,  7.8749,  9.3566],\n",
      "        [ 5.1304,  2.5105,  5.3194,  6.4348],\n",
      "        [ 4.8312,  2.8132, 10.0844,  3.0155],\n",
      "        [11.8382,  2.3520, 11.5333,  7.9968],\n",
      "        [ 9.4870,  6.8454, 10.6999,  8.5880],\n",
      "        [ 4.4240,  7.6664,  4.0481,  7.5742],\n",
      "        [ 7.8643,  7.8734,  7.4320,  5.9348],\n",
      "        [ 4.6964,  8.5906,  5.7424,  8.9254],\n",
      "        [ 7.6642,  4.5987,  9.8764,  8.1109],\n",
      "        [ 8.6750,  6.6850,  9.8269,  7.1530],\n",
      "        [10.6481,  6.3847,  4.4089,  9.3803],\n",
      "        [ 6.4858,  5.3653,  6.4393,  6.6165],\n",
      "        [ 5.3826,  8.7987, 11.2502,  6.0380],\n",
      "        [10.4713,  4.7957,  7.3649,  8.5252],\n",
      "        [ 7.0615,  4.9383,  8.2451,  5.6433],\n",
      "        [ 9.6600,  3.0382,  7.4844,  5.8216],\n",
      "        [11.5917,  9.5813,  5.7250,  6.1838],\n",
      "        [ 7.4874,  4.4992,  6.9175,  4.8911],\n",
      "        [ 6.0851,  2.9317,  7.5829,  9.0619],\n",
      "        [ 5.3107,  3.9013,  7.6660,  5.5883],\n",
      "        [ 6.1679,  3.8177, 10.7197,  3.5642],\n",
      "        [11.7084,  9.9507,  7.1834,  5.4358],\n",
      "        [ 4.7737,  5.4262, 11.2383,  5.1172],\n",
      "        [ 5.0504,  4.6423,  6.9078,  2.0966],\n",
      "        [10.5065,  5.5865,  8.0439,  8.5138]])\n",
      "tensor([[0.0299, 0.0221, 0.0293, 0.0356, 0.1326, 0.1235, 0.1118, 0.0925, 0.0843,\n",
      "         0.0839, 0.0782, 0.0674, 0.0557, 0.0352, 0.0435, 0.0832, 0.0989, 0.1427,\n",
      "         0.1663, 0.2114, 0.2813, 0.3137, 0.3155, 0.2631, 0.0453],\n",
      "        [1.5898, 3.4590, 4.3788, 4.5291, 2.9610, 1.3151, 0.8628, 0.5790, 0.4670,\n",
      "         0.3745, 0.3114, 0.2770, 0.2194, 4.0335, 5.5793, 6.0313, 5.9782, 5.7089,\n",
      "         5.4829, 5.2124, 4.5452, 4.1840, 2.8687, 1.8850, 4.5949],\n",
      "        [0.8844, 2.3278, 3.0468, 2.0647, 0.0788, 0.0820, 0.0765, 0.0627, 0.0728,\n",
      "         0.0660, 0.0450, 0.0442, 0.0569, 2.5780, 4.2239, 4.5116, 4.1354, 3.0449,\n",
      "         2.4689, 1.9186, 1.0327, 0.6872, 0.1373, 0.1359, 3.9243],\n",
      "        [0.5548, 1.5238, 2.2622, 2.8023, 3.1155, 2.1656, 1.3741, 0.7745, 0.4254,\n",
      "         0.2462, 0.1537, 0.0937, 0.0561, 1.4476, 2.4789, 3.2548, 3.3886, 3.6493,\n",
      "         3.7758, 3.8248, 3.9442, 3.9619, 4.7166, 4.3100, 1.9958],\n",
      "        [0.9764, 2.8398, 4.4605, 5.5103, 5.7601, 3.5312, 2.0984, 1.1889, 0.6962,\n",
      "         0.4198, 0.2394, 0.1367, 0.0613, 2.7335, 4.7895, 6.4360, 6.7517, 7.2391,\n",
      "         7.4128, 7.5365, 7.6371, 7.6399, 7.0582, 5.3440, 4.3059],\n",
      "        [0.8840, 2.4855, 3.2934, 3.4143, 1.7076, 0.5770, 0.4806, 0.3933, 0.3264,\n",
      "         0.2802, 0.2371, 0.1944, 0.1785, 2.6269, 3.7980, 4.0402, 3.9642, 3.6022,\n",
      "         3.3212, 3.0136, 2.2827, 1.9131, 1.4020, 1.1975, 3.0983],\n",
      "        [0.3008, 0.4704, 0.4449, 0.3841, 0.2701, 0.1991, 0.1787, 0.1410, 0.1258,\n",
      "         0.1144, 0.0966, 0.0920, 0.0801, 1.1039, 1.2408, 1.1134, 1.0672, 0.9682,\n",
      "         0.9142, 0.8769, 0.7805, 0.7368, 0.6039, 0.4792, 1.0589],\n",
      "        [0.4006, 0.6091, 0.5504, 0.4423, 0.2802, 0.1914, 0.1770, 0.1316, 0.1124,\n",
      "         0.1078, 0.0913, 0.0757, 0.0776, 1.5005, 1.6172, 1.3645, 1.2898, 1.1355,\n",
      "         1.0562, 0.9914, 0.8546, 0.7983, 0.6212, 0.4987, 1.4372],\n",
      "        [0.0170, 0.0315, 0.0198, 0.0210, 0.0230, 0.0352, 0.0158, 0.0245, 0.0163,\n",
      "         0.0167, 0.0222, 0.0178, 0.0167, 0.0168, 0.0221, 0.0235, 0.0144, 0.0191,\n",
      "         0.0197, 0.0305, 0.0216, 0.0192, 0.0390, 0.0150, 0.0167],\n",
      "        [0.4736, 0.9194, 1.1949, 1.3727, 1.7020, 1.0189, 0.2502, 0.0146, 0.0105,\n",
      "         0.0090, 0.0145, 0.0140, 0.0147, 1.4086, 1.9873, 2.4259, 2.5076, 2.7306,\n",
      "         2.8171, 2.9323, 3.1659, 3.2556, 3.3902, 2.5777, 2.2940],\n",
      "        [1.9358, 4.2276, 4.8030, 2.7045, 0.2566, 0.1841, 0.1652, 0.1415, 0.1232,\n",
      "         0.1182, 0.1059, 0.0868, 0.0841, 4.2336, 6.1750, 5.8823, 5.1361, 3.2578,\n",
      "         2.4157, 1.6970, 0.6275, 0.4791, 0.4068, 0.3251, 5.2482],\n",
      "        [0.9120, 2.4015, 3.4146, 3.9245, 3.7753, 2.2661, 1.3699, 0.7322, 0.4040,\n",
      "         0.2597, 0.1895, 0.1235, 0.0822, 1.9088, 3.3412, 4.3966, 4.5660, 4.8303,\n",
      "         4.9195, 4.9801, 4.9690, 4.9137, 4.4006, 3.3595, 2.8496],\n",
      "        [0.5280, 1.1198, 1.0389, 0.5290, 0.7851, 0.6110, 0.5298, 0.4615, 0.3912,\n",
      "         0.3370, 0.2957, 0.2696, 0.2420, 1.1923, 1.5539, 0.5044, 0.3955, 0.8174,\n",
      "         0.9862, 1.1368, 1.3021, 1.3188, 1.2555, 1.0671, 1.6838],\n",
      "        [0.5631, 1.4393, 1.9552, 2.0098, 0.5832, 0.4580, 0.3735, 0.3262, 0.2808,\n",
      "         0.2327, 0.2062, 0.1773, 0.1457, 1.2152, 1.9410, 2.0528, 1.9915, 1.6267,\n",
      "         1.3536, 1.0604, 0.9508, 1.0435, 1.1223, 0.9550, 1.2975],\n",
      "        [0.4227, 0.8101, 1.1461, 1.5424, 2.4931, 1.7676, 0.7986, 0.2548, 0.0120,\n",
      "         0.0169, 0.0217, 0.0178, 0.0171, 1.2299, 1.8159, 2.4977, 2.6958, 3.1471,\n",
      "         3.3988, 3.6579, 4.1787, 4.4249, 4.8730, 3.9631, 1.9880],\n",
      "        [1.4298, 3.7959, 4.6238, 3.6020, 1.1791, 0.3587, 0.1913, 0.0949, 0.0774,\n",
      "         0.0633, 0.0662, 0.0611, 0.0560, 4.7372, 7.0243, 7.1519, 6.7813, 5.6594,\n",
      "         5.0206, 4.3965, 3.2924, 2.8309, 1.5081, 0.7782, 6.2973],\n",
      "        [2.0156, 4.5349, 5.6765, 6.0015, 5.1363, 3.0958, 2.1766, 1.5309, 1.0961,\n",
      "         0.8023, 0.6015, 0.4590, 0.3587, 5.1114, 7.4412, 8.4225, 8.5104, 8.5452,\n",
      "         8.4942, 8.4070, 8.0947, 7.8628, 6.5987, 4.9305, 5.0604],\n",
      "        [0.7303, 2.6644, 4.3508, 5.1889, 4.6998, 2.8138, 2.0147, 1.4335, 1.0460,\n",
      "         0.7685, 0.5854, 0.4633, 0.3743, 2.4225, 5.0791, 7.0440, 7.3475, 7.7445,\n",
      "         7.8251, 7.8480, 7.7050, 7.5456, 6.4582, 4.8470, 3.3994],\n",
      "        [1.2238, 2.9844, 3.9024, 4.0803, 2.4700, 0.9141, 0.5641, 0.4481, 0.3696,\n",
      "         0.3044, 0.2645, 0.2268, 0.1898, 3.4317, 4.9283, 5.3443, 5.2867, 4.9772,\n",
      "         4.7340, 4.4215, 3.7169, 3.3532, 2.0535, 1.4123, 4.1645],\n",
      "        [1.8099, 3.9082, 4.7089, 4.6242, 2.6829, 1.1440, 0.7600, 0.5349, 0.4329,\n",
      "         0.3799, 0.3186, 0.2667, 0.2383, 3.8152, 5.3588, 5.6455, 5.5560, 5.1274,\n",
      "         4.8337, 4.4867, 3.7661, 3.3989, 2.1913, 1.5244, 3.8997],\n",
      "        [0.7378, 1.4950, 1.7034, 1.4206, 0.2738, 0.0197, 0.0337, 0.0261, 0.0226,\n",
      "         0.0209, 0.0208, 0.0199, 0.0176, 2.4225, 3.2138, 3.1543, 2.9956, 2.4560,\n",
      "         2.0985, 1.7326, 1.0035, 0.6689, 0.0476, 0.0549, 3.5633],\n",
      "        [0.3873, 1.5212, 2.5537, 3.0609, 2.7585, 1.8246, 1.3882, 1.0408, 0.7625,\n",
      "         0.5614, 0.4261, 0.3286, 0.2452, 1.4423, 3.1477, 4.4619, 4.6648, 4.9205,\n",
      "         4.9814, 4.9881, 4.8803, 4.7877, 4.1102, 3.2553, 2.1776],\n",
      "        [1.2994, 3.0083, 3.7702, 3.7260, 1.7715, 0.5628, 0.3213, 0.1899, 0.1480,\n",
      "         0.1356, 0.1190, 0.1061, 0.0925, 3.5499, 4.9949, 5.2123, 5.0820, 4.5880,\n",
      "         4.2262, 3.8226, 2.9247, 2.5049, 1.2823, 0.6731, 4.1534],\n",
      "        [1.1023, 2.1457, 2.3142, 1.9214, 0.7025, 0.2585, 0.1623, 0.1095, 0.0763,\n",
      "         0.0481, 0.0334, 0.0247, 0.0228, 3.9291, 5.0546, 4.8689, 4.6432, 4.0043,\n",
      "         3.6077, 3.1816, 2.3765, 2.0198, 1.0334, 0.5647, 5.3473],\n",
      "        [1.8929, 3.4236, 3.4750, 2.9351, 1.6921, 0.9343, 0.7039, 0.5527, 0.4365,\n",
      "         0.3670, 0.2862, 0.2564, 0.2152, 4.4092, 5.2654, 4.7535, 4.5301, 4.0074,\n",
      "         3.7336, 3.4608, 2.9283, 2.6905, 1.8796, 1.3206, 3.4774],\n",
      "        [1.0544, 2.2777, 2.5854, 2.2889, 0.8599, 0.3153, 0.1947, 0.1397, 0.0841,\n",
      "         0.0546, 0.0363, 0.0323, 0.0283, 3.8523, 5.1847, 5.1373, 4.9405, 4.3059,\n",
      "         3.8994, 3.4474, 2.5739, 2.1898, 1.1216, 0.5936, 5.1486],\n",
      "        [0.5518, 1.8366, 2.8557, 3.4459, 3.0669, 1.4663, 0.8957, 0.5177, 0.3578,\n",
      "         0.2806, 0.2215, 0.1777, 0.1452, 1.7465, 3.3720, 4.4545, 4.6127, 4.7904,\n",
      "         4.8030, 4.7875, 4.5698, 4.4036, 3.3781, 2.2424, 2.6860],\n",
      "        [1.6785, 3.0035, 2.9654, 2.5432, 1.6884, 1.1178, 0.9212, 0.7746, 0.6482,\n",
      "         0.5550, 0.4815, 0.4273, 0.3548, 4.0439, 4.8153, 4.4584, 4.3107, 3.9497,\n",
      "         3.7655, 3.5944, 3.2185, 3.0412, 2.4150, 1.8925, 3.1716],\n",
      "        [0.8545, 1.3713, 1.3034, 1.1063, 0.6918, 0.4484, 0.3549, 0.2936, 0.2533,\n",
      "         0.2127, 0.1830, 0.1579, 0.1433, 2.7930, 3.2786, 2.9687, 2.8262, 2.5641,\n",
      "         2.4111, 2.2814, 2.0062, 1.8707, 1.4297, 1.0829, 2.4831],\n",
      "        [1.2766, 2.7548, 3.5886, 3.8920, 3.4719, 2.0965, 1.4667, 0.9588, 0.6376,\n",
      "         0.4284, 0.3191, 0.2260, 0.1581, 2.9124, 4.1536, 4.7861, 4.8795, 4.9518,\n",
      "         4.9414, 4.9129, 4.8179, 4.7287, 4.6663, 4.1335, 3.5434]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network successfully converged after 49 epochs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74c86e336264074a3456166c419eda9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6822a06e420f45a7b1d9c0da8698e336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2b569f950a47eaae841fd3b5034b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[ 8.6131,  4.8724, 10.5705,  9.4767],\n",
      "        [ 4.6850,  5.0469,  7.1557,  5.0192],\n",
      "        [ 7.8015,  3.1387,  8.3547,  4.6339],\n",
      "        [ 6.0545,  3.9193,  7.7340,  5.7414],\n",
      "        [ 6.2659,  8.6878,  7.0400,  5.1597],\n",
      "        [ 8.5495,  3.7762,  9.1768,  5.2996],\n",
      "        [ 8.2522,  5.8913, 10.5930,  5.8692],\n",
      "        [ 8.3512,  3.7450, 10.5777,  9.1325],\n",
      "        [10.3476,  5.9245,  6.1134,  6.4420],\n",
      "        [ 9.2854,  6.5436,  8.0842,  5.7484],\n",
      "        [ 8.0265,  5.0544,  8.8147,  7.0715],\n",
      "        [ 7.3687,  5.1758,  9.4852,  5.8829],\n",
      "        [ 9.3943,  8.5701, 10.8255,  7.8029],\n",
      "        [ 7.4160,  3.8375,  8.4493,  7.2160],\n",
      "        [ 8.0003,  7.8589,  8.9141,  6.3379],\n",
      "        [11.9601,  3.7036,  7.8018,  4.1846],\n",
      "        [ 4.0293,  6.6542,  7.1506,  9.4136],\n",
      "        [ 6.6295,  7.5939,  9.3765,  7.5585],\n",
      "        [ 8.7545,  5.5305,  5.7251,  5.9513],\n",
      "        [ 7.3205,  3.8841,  9.0268,  6.5180],\n",
      "        [ 6.5871,  3.3090,  9.3247,  6.4012],\n",
      "        [10.4291,  2.2691,  7.8370,  6.9612],\n",
      "        [ 7.3222,  2.7415,  7.2053,  9.1659],\n",
      "        [ 8.1150,  7.5583,  9.9159,  5.8792],\n",
      "        [ 9.7425,  2.1771,  7.7787,  7.6033],\n",
      "        [10.9992,  3.0016,  8.4555,  9.0430],\n",
      "        [10.5691,  8.0483,  7.6757,  8.8947],\n",
      "        [10.8207,  6.2671, 10.7669,  7.0486],\n",
      "        [ 9.4846,  6.4430,  6.0890,  8.3547],\n",
      "        [ 8.9708,  7.1150, 10.6412,  7.9540]])\n",
      "tensor([[0.0521, 0.0816, 0.1253, 0.2330, 0.8603, 0.7892, 0.6374, 0.5154, 0.4189,\n",
      "         0.3441, 0.2996, 0.2489, 0.2054, 0.1195, 0.2005, 0.4053, 0.5034, 0.7508,\n",
      "         0.9292, 1.1397, 1.5543, 1.7246, 1.9182, 1.6192, 0.2140],\n",
      "        [1.2953, 2.1289, 2.0584, 1.7600, 1.2167, 0.8589, 0.7239, 0.6230, 0.5432,\n",
      "         0.4640, 0.4066, 0.3681, 0.3274, 2.9302, 3.4470, 3.1591, 3.0561, 2.7950,\n",
      "         2.6827, 2.5576, 2.3225, 2.2075, 1.7926, 1.4698, 2.1657],\n",
      "        [0.6105, 1.2143, 1.3408, 0.9794, 0.0195, 0.0177, 0.0147, 0.0262, 0.0291,\n",
      "         0.0162, 0.0183, 0.0240, 0.0161, 1.6937, 2.2721, 2.0990, 1.9284, 1.3664,\n",
      "         1.0041, 0.6140, 0.0435, 0.0448, 0.0456, 0.0343, 2.2965],\n",
      "        [2.1443, 4.3464, 5.0352, 4.7392, 2.3725, 0.9083, 0.6058, 0.4202, 0.2935,\n",
      "         0.2223, 0.1672, 0.1215, 0.1017, 5.3188, 6.9364, 6.8685, 6.6351, 5.9178,\n",
      "         5.4616, 4.9345, 3.8593, 3.3778, 1.8714, 1.0792, 5.5995],\n",
      "        [0.5983, 2.3007, 3.7491, 4.4683, 3.8620, 1.9488, 1.3086, 0.9073, 0.6367,\n",
      "         0.4705, 0.3553, 0.2791, 0.2109, 1.9534, 4.1933, 5.7290, 5.9443, 6.1810,\n",
      "         6.1993, 6.1627, 5.8708, 5.6539, 4.3443, 2.8993, 2.9652],\n",
      "        [0.2889, 0.4329, 0.3178, 0.0347, 0.0922, 0.0773, 0.0722, 0.0635, 0.0534,\n",
      "         0.0527, 0.0473, 0.0447, 0.0331, 0.4380, 0.3206, 0.0499, 0.0681, 0.0903,\n",
      "         0.1063, 0.1250, 0.1600, 0.1646, 0.1681, 0.1431, 0.2205],\n",
      "        [0.1317, 0.2246, 0.3764, 0.6955, 2.0591, 1.9537, 1.4170, 0.9661, 0.6471,\n",
      "         0.4547, 0.3168, 0.2368, 0.1834, 0.3852, 0.6270, 1.1191, 1.3331, 1.8601,\n",
      "         2.1845, 2.5481, 3.2933, 3.6202, 4.2490, 3.7861, 0.6515],\n",
      "        [0.0207, 0.0324, 0.0350, 0.0294, 0.0872, 0.0753, 0.0684, 0.0483, 0.0580,\n",
      "         0.0535, 0.0410, 0.0373, 0.0468, 0.0261, 0.0258, 0.0504, 0.0628, 0.0886,\n",
      "         0.0910, 0.1160, 0.1610, 0.1727, 0.1816, 0.1477, 0.0355],\n",
      "        [1.6589, 3.8171, 4.9825, 5.4281, 4.9105, 3.1819, 2.2343, 1.5193, 1.0358,\n",
      "         0.7168, 0.5192, 0.3905, 0.2817, 4.6446, 6.9418, 8.0997, 8.2360, 8.3863,\n",
      "         8.3980, 8.3677, 8.1734, 8.0080, 7.0025, 5.4877, 5.1145],\n",
      "        [1.2954, 2.7904, 3.5558, 3.7917, 3.1009, 1.5633, 0.9573, 0.6655, 0.4515,\n",
      "         0.3128, 0.2405, 0.1740, 0.1326, 2.8710, 4.0465, 4.5892, 4.6360, 4.6211,\n",
      "         4.5668, 4.4931, 4.2647, 4.1000, 3.2745, 2.7242, 3.4097],\n",
      "        [0.9195, 1.7975, 2.1042, 2.0271, 1.2187, 1.0952, 0.8512, 0.6852, 0.5208,\n",
      "         0.4202, 0.3416, 0.2782, 0.2263, 1.7325, 2.3335, 2.3515, 2.2632, 1.9825,\n",
      "         1.7887, 1.6056, 2.1407, 2.3537, 2.6137, 2.2378, 1.8008],\n",
      "        [1.0852, 2.6239, 3.3979, 3.5298, 2.3795, 1.2224, 0.9864, 0.7828, 0.6017,\n",
      "         0.4800, 0.3834, 0.3102, 0.2565, 2.3248, 3.5718, 4.0200, 4.0078, 3.8206,\n",
      "         3.6773, 3.5014, 3.1084, 2.9002, 2.7264, 2.4182, 2.4893],\n",
      "        [0.3536, 0.7237, 0.8736, 0.8790, 0.5655, 0.0094, 0.0277, 0.0133, 0.0219,\n",
      "         0.0150, 0.0162, 0.0252, 0.0114, 1.0426, 1.4153, 1.5620, 1.5554, 1.5361,\n",
      "         1.5200, 1.4920, 1.4110, 1.3349, 0.8631, 0.0145, 1.6170],\n",
      "        [1.3169, 2.7534, 3.2843, 3.1195, 1.0340, 0.0811, 0.0752, 0.0628, 0.0596,\n",
      "         0.0596, 0.0444, 0.0551, 0.0369, 2.7491, 3.8520, 3.9006, 3.7471, 3.1442,\n",
      "         2.7794, 2.3009, 1.3185, 0.8740, 0.2184, 0.1758, 2.9121],\n",
      "        [0.6437, 1.3946, 1.8142, 2.0820, 2.1146, 1.6688, 0.9741, 0.4925, 0.2395,\n",
      "         0.1202, 0.0595, 0.0352, 0.0240, 1.3388, 2.0387, 2.4303, 2.5032, 2.6102,\n",
      "         2.6614, 2.6626, 2.6334, 2.6067, 3.2892, 3.3497, 1.7365],\n",
      "        [0.7667, 1.5776, 1.8322, 1.5817, 0.2216, 0.0444, 0.0372, 0.0287, 0.0444,\n",
      "         0.0287, 0.0245, 0.0298, 0.0245, 2.2052, 2.9488, 2.8369, 2.6661, 2.1178,\n",
      "         1.7507, 1.3720, 0.5906, 0.2531, 0.0780, 0.0760, 2.9946],\n",
      "        [1.9073, 5.0352, 5.9833, 3.9422, 0.9259, 0.2505, 0.1558, 0.1356, 0.1091,\n",
      "         0.1071, 0.1073, 0.0916, 0.0824, 5.6080, 8.2052, 8.0518, 7.3140, 5.3427,\n",
      "         4.3810, 3.5574, 2.3311, 1.8763, 0.7890, 0.3087, 6.9297],\n",
      "        [1.7665, 4.1698, 5.5412, 6.1467, 5.8787, 3.4513, 1.9688, 1.0655, 0.5654,\n",
      "         0.2784, 0.1074, 0.0239, 0.0202, 4.0727, 6.2445, 7.5171, 7.7043, 7.9720,\n",
      "         8.0385, 8.0510, 7.9756, 7.8871, 7.0215, 5.1551, 5.3026],\n",
      "        [1.0529, 2.4735, 3.2381, 3.5103, 3.1395, 2.2085, 1.7330, 1.3318, 1.0197,\n",
      "         0.7871, 0.6066, 0.4755, 0.3879, 3.1029, 4.7514, 5.5735, 5.6788, 5.7665,\n",
      "         5.7557, 5.7248, 5.5706, 5.4527, 4.8167, 3.9080, 3.0501],\n",
      "        [1.1792, 2.5890, 3.1910, 3.1156, 1.1171, 0.1038, 0.0938, 0.0755, 0.0684,\n",
      "         0.0651, 0.0634, 0.0562, 0.0488, 2.4720, 3.5867, 3.7455, 3.5919, 3.0594,\n",
      "         2.6803, 2.2619, 1.3297, 0.8800, 0.2587, 0.2202, 2.6155],\n",
      "        [1.0349, 2.2833, 2.6876, 2.3994, 0.8845, 0.2565, 0.1341, 0.0579, 0.0322,\n",
      "         0.0357, 0.0247, 0.0242, 0.0231, 3.2887, 4.6110, 4.6682, 4.5083, 3.9130,\n",
      "         3.5216, 3.0818, 2.1970, 1.8225, 0.7622, 0.2724, 4.2235],\n",
      "        [0.5698, 1.0990, 1.1863, 0.8231, 0.0182, 0.0103, 0.0248, 0.0192, 0.0104,\n",
      "         0.0185, 0.0279, 0.0162, 0.0230, 1.8520, 2.4357, 2.2781, 2.0993, 1.5869,\n",
      "         1.2486, 0.9056, 0.2622, 0.0298, 0.0198, 0.0289, 2.8707],\n",
      "        [0.7922, 1.6157, 1.8039, 1.4560, 0.3731, 0.0506, 0.0237, 0.0144, 0.0176,\n",
      "         0.0180, 0.0269, 0.0178, 0.0157, 2.6612, 3.5928, 3.5744, 3.4232, 2.8654,\n",
      "         2.5160, 2.1400, 1.4061, 1.0989, 0.2958, 0.0302, 4.0650],\n",
      "        [0.1803, 0.4003, 0.5512, 0.6663, 0.9871, 1.3606, 1.0017, 0.6654, 0.4112,\n",
      "         0.2707, 0.1862, 0.1463, 0.1214, 0.3637, 0.5574, 0.6366, 0.6372, 0.6703,\n",
      "         0.7973, 0.9351, 1.2943, 1.5213, 2.4062, 2.6534, 0.4914],\n",
      "        [0.5699, 1.1229, 1.1994, 0.8385, 0.0140, 0.0233, 0.0177, 0.0225, 0.0215,\n",
      "         0.0211, 0.0218, 0.0109, 0.0240, 1.9022, 2.4950, 2.3589, 2.1881, 1.6561,\n",
      "         1.3424, 1.0004, 0.3543, 0.0829, 0.0210, 0.0229, 2.9903],\n",
      "        [0.4558, 0.8662, 0.8752, 0.5028, 0.0276, 0.0222, 0.0257, 0.0260, 0.0262,\n",
      "         0.0215, 0.0261, 0.0149, 0.0259, 1.2490, 1.5495, 1.2328, 1.0251, 0.4545,\n",
      "         0.0920, 0.0504, 0.0462, 0.0435, 0.0448, 0.0350, 1.6346],\n",
      "        [0.8664, 1.9884, 2.7417, 3.1707, 3.2246, 1.4186, 0.2415, 0.0274, 0.0147,\n",
      "         0.0117, 0.0125, 0.0124, 0.0208, 1.9739, 2.9730, 3.5704, 3.6804, 3.7855,\n",
      "         3.8017, 3.8382, 3.7399, 3.6614, 3.0359, 1.7572, 2.9302],\n",
      "        [0.3577, 0.6672, 1.0048, 1.4779, 2.9116, 2.3687, 1.2859, 0.6329, 0.3048,\n",
      "         0.1303, 0.0295, 0.0254, 0.0221, 1.0190, 1.5800, 2.3684, 2.6322, 3.2391,\n",
      "         3.5767, 3.9481, 4.6882, 5.0445, 5.7000, 4.8349, 1.6716],\n",
      "        [1.7763, 4.0994, 5.2801, 5.3085, 4.1008, 2.6701, 1.8928, 1.2723, 0.8319,\n",
      "         0.5476, 0.3578, 0.2397, 0.1599, 4.8573, 7.2308, 8.1099, 8.0849, 7.8191,\n",
      "         7.6027, 7.3549, 6.8371, 6.5750, 5.5582, 4.3614, 6.4475],\n",
      "        [0.4872, 0.9555, 1.2175, 1.3776, 1.6081, 0.8997, 0.0892, 0.0223, 0.0315,\n",
      "         0.0312, 0.0181, 0.0235, 0.0239, 1.4199, 1.9749, 2.3397, 2.4298, 2.5704,\n",
      "         2.6346, 2.7089, 2.8401, 2.8849, 2.8502, 1.9568, 2.2586]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training neural network. Epochs trained:  34\r"
     ]
    }
   ],
   "source": [
    "infer = SnpeC(sample_with_mcmc=False, **snpe_common_args)\n",
    "\n",
    "# Run inference.\n",
    "num_rounds, num_simulations_per_round = 3, 30\n",
    "posterior = infer(\n",
    "    num_rounds=num_rounds, num_simulations_per_round=num_simulations_per_round, batch_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the results\n",
    "\n",
    "After running the inference algorithm, let us inspect and analyse the results. It seems that the loss function has converged. Let us inspect the inferred posterior distribution over the parameters ($\\bar g_{Na}$,$\\bar g_K$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# colors\n",
    "hex2rgb = lambda h: tuple(int(h[i:i+2], 16) for i in (0, 2, 4))\n",
    "\n",
    "# RGB colors in [0, 255]\n",
    "col = {}\n",
    "col['GT']      = hex2rgb('30C05D')\n",
    "col['SNPE']    = hex2rgb('2E7FE8')\n",
    "col['SAMPLE1'] = hex2rgb('8D62BC')\n",
    "col['SAMPLE2'] = hex2rgb('AF99EF')\n",
    "\n",
    "# convert to RGB colors in [0, 1]\n",
    "for k, v in col.items():\n",
    "    col[k] = tuple([i/255 for i in v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = posterior.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = utils.samples_nd(utils.tensor2numpy(samples),\n",
    "                       limits=np.asarray([prior_min, prior_max]).T,\n",
    "                       ticks=np.asarray([prior_min, prior_max]).T,\n",
    "                       fig_size=(5,5),\n",
    "                       diag='kde',\n",
    "                       upper='kde',\n",
    "                       hist_diag={'bins': 50},\n",
    "                       hist_offdiag={'bins': 50},\n",
    "                       kde_diag={'bins': 50, 'color': col['GT']},\n",
    "                       kde_offdiag={'bins': 50},\n",
    "                       points=[true_params],\n",
    "                       points_offdiag={'markersize': 5},\n",
    "                       points_colors='g',\n",
    "                       title='');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the inferred posterior contains the ground-truth parameters (green) in a high-probability region. Now, let us sample parameters from the posterior distribution, simulate the Hodgkin-Huxley model for each of those samples and compare the simulations with the observed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_obs = observation_trace['data']\n",
    "t = observation_trace['time']\n",
    "duration = np.max(t)\n",
    "\n",
    "num_samp = 2\n",
    "\n",
    "# sample from posterior\n",
    "x_samp = posterior.sample(num_samples=1000)\n",
    "\n",
    "x_samp = np.median(x_samp.detach().numpy(), axis=0)\n",
    "\n",
    "#x_samp = [ 7.682584,    5.845819,    8.078228,    6.199831,   -6.098556,   -6.454344,\n",
    "# -6.7167273,  -8.592197,   -0.01400174, -0.0039]\n",
    "\n",
    "#[8.886491e+00,  7.924279e+00,\n",
    "#1.050515e+01,  7.397940e+00, -3.682371e+00, -4.509306e+00, -6.162727e+00,\n",
    "#-6.585027e+00,  1.100000e-03, -3.900000e-01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,5))\n",
    "\n",
    "col_min = 1\n",
    "num_colors = num_samp+col_min\n",
    "cm1 = mpl.cm.Blues\n",
    "col1 = [cm1(1.*i/num_colors) for i in range(col_min,num_colors)]\n",
    "\n",
    "# reject samples for which prior is zero\n",
    "#ind = (x_samp > prior_min) & (x_samp < prior_max)\n",
    "#params = x_samp[np.prod(ind,axis=1)==1]\n",
    "params = x_samp\n",
    "#num_samp = len(params[:,0])\n",
    "\n",
    "# simulate and plot samples\n",
    "post_samples = np.zeros((num_samp, 94 ,259))\n",
    "post_samples = run_faas_model(params=params)['data']\n",
    "\n",
    "    \n",
    "for j in np.arange(92//4):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "    ax1.plot(t,observation_trace['data'][j*4,:],lw=2)\n",
    "    ax1.set_title(str(j*4+1))\n",
    "    ax2.plot(t,observation_trace['data'][j*4+1,:],lw=2)\n",
    "    ax2.set_title(str(j*4+2))\n",
    "    ax3.plot(t,observation_trace['data'][j*4+2,:],lw=2)\n",
    "    ax3.set_title(str(j*4+3))\n",
    "    ax4.plot(t,observation_trace['data'][j*4+3,:],lw=2)\n",
    "    ax4.set_title(str(j*4+4))\n",
    "\n",
    "    #for i in range(num_samp):\n",
    "    ax1.plot(t,post_samples[j*4,:],color=col1[0],lw=2, label = str(0))\n",
    "    ax1.set_title(str(j*4+1))\n",
    "    ax2.plot(t,post_samples[j*4+1,:],color=col1[0],lw=2, label = str(0))\n",
    "    ax2.set_title(str(j*4+2))\n",
    "    ax3.plot(t,post_samples[j*4+2,:],color=col1[0],lw=2, label = str(0))\n",
    "    ax3.set_title(str(j*4+3))\n",
    "    ax4.plot(t,post_samples[j*4+3,:],color=col1[0],lw=2, label = str(0))\n",
    "    ax4.set_title(str(j*4+4))\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    fig.tight_layout()\n",
    "    \n",
    "plt.figure(figsize=(20,10))\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)        \n",
    "\n",
    "ax1.plot(t,observation_trace['data'][92,:],lw=2)\n",
    "ax1.set_title(str(93))\n",
    "ax2.plot(t,observation_trace['data'][93,:],lw=2)\n",
    "ax2.set_title(str(94))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the samples from the inferred posterior lead to simulations that closely resemble the observed data, confirming that `SNPE-C` did a good job at capturing the observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "\n",
    "A. L. Hodgkin and A. F. Huxley. A quantitative description of membrane current and its application to conduction and excitation in nerve. The Journal of Physiology, 117(4):500–544, 1952.\n",
    "\n",
    "M. Pospischil, M. Toledo-Rodriguez, C. Monier, Z. Piwkowska, T. Bal, Y. Frégnac, H. Markram, and A. Destexhe. Minimal Hodgkin-Huxley type models for different classes of cortical and thalamic neurons. Biological Cybernetics, 99(4-5), 2008."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
