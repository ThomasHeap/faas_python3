{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Import your stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emcee\n",
    "from scipy.optimize import minimize\n",
    "from getdist import plots, MCSamples\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import simulator as faas\n",
    "import pydelfi.ndes as ndes\n",
    "import pydelfi.delfi as delfi\n",
    "import pydelfi.score as score\n",
    "import pydelfi.priors as priors\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "%matplotlib inline\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Set up the prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper = np.array([12,  12,\n",
    "  12,  12, -2, -2, -2,\n",
    " -2])\n",
    "lower = np.array([6,  6,\n",
    "  6,  6, -8, -8, -8,\n",
    " -8])\n",
    "\n",
    "prior_mean = np.array([1.1e-03, -3.9e-01])\n",
    "prior_cov = np.diag(np.array([(0.0011*0.2)**2, (0.39*0.2)**2]))\n",
    "\n",
    "prior = priors.Gaussian_Unif(prior_mean, prior_cov, lower, upper, 2)\n",
    "\n",
    "epsilon_mean = np.array([0]*94)\n",
    "epsilon_cov = np.diag(np.array([0.5] * 94))\n",
    "epsilon_prior = priors.Gaussian(epsilon_mean, epsilon_cov)\n",
    "\n",
    "#print(faasSimulator.exp(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Set up the simulator\n",
    "This must have the signature `simulator(parameters, seed, args, batch)` -> `np.array([batch, ndata])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/anaconda3/envs/thesis/lib/python3.6/site-packages/scipy/integrate/odepack.py:247: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "/home/thomas/anaconda3/envs/thesis/lib/python3.6/site-packages/scipy/integrate/odepack.py:247: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "/home/thomas/Thesis/pydelfi/examples/simulators/faas_python3/postFLASH.py:112: RuntimeWarning: overflow encountered in multiply\n",
      "  F_ratio_course = (post_out[relevantID, 7] + float(F_ratio)*post_out[relevantID, 8])/(pre_out[\"OGB5N\"] + float(F_ratio)*pre_out[\"CaOGB5N\"])\n",
      "/home/thomas/Thesis/pydelfi/examples/simulators/faas_python3/postFLASH.py:112: RuntimeWarning: overflow encountered in true_divide\n",
      "  F_ratio_course = (post_out[relevantID, 7] + float(F_ratio)*post_out[relevantID, 8])/(pre_out[\"OGB5N\"] + float(F_ratio)*pre_out[\"CaOGB5N\"])\n",
      "/home/thomas/Thesis/pydelfi/examples/simulators/faas_python3/postFLASH.py:112: RuntimeWarning: overflow encountered in true_divide\n",
      "  F_ratio_course = (post_out[relevantID, 7] + float(F_ratio)*post_out[relevantID, 8])/(pre_out[\"OGB5N\"] + float(F_ratio)*pre_out[\"CaOGB5N\"])\n",
      "/home/thomas/anaconda3/envs/thesis/lib/python3.6/site-packages/scipy/integrate/odepack.py:247: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  warnings.warn(warning_msg, ODEintWarning)\n",
      "/home/thomas/Thesis/pydelfi/examples/simulators/faas_python3/postFLASH.py:112: RuntimeWarning: overflow encountered in multiply\n",
      "  F_ratio_course = (post_out[relevantID, 7] + float(F_ratio)*post_out[relevantID, 8])/(pre_out[\"OGB5N\"] + float(F_ratio)*pre_out[\"CaOGB5N\"])\n",
      "/home/thomas/Thesis/pydelfi/examples/simulators/faas_python3/postFLASH.py:112: RuntimeWarning: invalid value encountered in multiply\n",
      "  F_ratio_course = (post_out[relevantID, 7] + float(F_ratio)*post_out[relevantID, 8])/(pre_out[\"OGB5N\"] + float(F_ratio)*pre_out[\"CaOGB5N\"])\n",
      "/home/thomas/Thesis/pydelfi/examples/simulators/faas_python3/postFLASH.py:112: RuntimeWarning: invalid value encountered in add\n",
      "  F_ratio_course = (post_out[relevantID, 7] + float(F_ratio)*post_out[relevantID, 8])/(pre_out[\"OGB5N\"] + float(F_ratio)*pre_out[\"CaOGB5N\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.00000000e+000  1.00000000e+000  2.09200000e+000  1.00000000e+000\n",
      "  1.00000000e+000  2.09200000e+000  1.00000000e+000  1.00000000e+000\n",
      "  2.09200000e+000  1.00000000e+000  1.00000000e+000  2.09200000e+000\n",
      "  1.00000000e+000  1.00000000e+000  2.09200000e+000  1.00000000e+000\n",
      "  1.00000000e+000  2.09200000e+000  1.00000000e+000  1.00000000e+000\n",
      "  2.09200000e+000  1.00000000e+000  1.00000000e+000  2.09200000e+000\n",
      "  1.00000000e+000  1.00000000e+000  2.09200000e+000  1.00000000e+000\n",
      "  1.00000000e+000  2.09200000e+000  1.00000000e+000  1.00000000e+000\n",
      "  2.09200000e+000  1.00000000e+000  1.00000000e+000  2.09200000e+000\n",
      "  1.00000000e+000  1.00000000e+000  2.09200000e+000  1.00000000e+000\n",
      "  1.00000000e+000  1.60400000e+000  1.00000000e+000  1.00000000e+000\n",
      "  1.60400000e+000  1.00000000e+000  1.00000000e+000  1.60400000e+000\n",
      "  1.00000000e+000  1.00000000e+000  1.60400000e+000  1.00000000e+000\n",
      "  1.00000000e+000  1.60400000e+000  1.00000000e+000  1.00000000e+000\n",
      "  1.60400000e+000  1.00000000e+000  1.00000000e+000  1.60400000e+000\n",
      "  1.00000000e+000  1.00000000e+000  1.60400000e+000  1.00000000e+000\n",
      "  1.00000000e+000  1.60400000e+000  8.49301263e+000  8.49311891e+000\n",
      "  1.10600000e+001  1.00000000e+000  1.00000000e+000  1.60400000e+000\n",
      "  1.00000000e+000  1.00000000e+000  1.58800000e+000  1.00000000e+000\n",
      "  1.00000000e+000  1.58800000e+000  1.00000000e+000  1.00000000e+000\n",
      "  1.58800000e+000  1.00000000e+000  1.00000000e+000  1.58800000e+000\n",
      "  1.00000000e+000  1.00000000e+000  1.58800000e+000  1.00000000e+000\n",
      "  1.00000000e+000  1.58800000e+000  1.05491642e+001  1.05500193e+001\n",
      "  1.10600000e+001  1.00000000e+000  1.00000000e+000  1.58800000e+000\n",
      "  1.00000000e+000  1.00000000e+000  1.58800000e+000  1.00000000e+000\n",
      "  1.00000000e+000  1.58800000e+000  1.00000000e+000  1.00000000e+000\n",
      "  1.58800000e+000  4.41998146e+000  5.89216177e+000  3.00000000e-001\n",
      " -3.13447436e+113  5.45430127e+243  5.72000000e-001  7.93184121e+279\n",
      "              nan  4.04000000e-001  1.85627051e+299  1.85627051e+300\n",
      "  3.52040000e+001  1.71711253e+000  2.08818068e+000  4.28000000e-001\n",
      "  1.71711253e+000  2.08818068e+000  4.28000000e-001  9.03828917e+276\n",
      "              nan  1.65200000e+000  4.56422186e-300              nan\n",
      "  1.87200000e+000              nan              nan  6.36000000e-001\n",
      "  9.32539832e+000  9.61043715e+000  2.68000000e-001  2.94387913e-316\n",
      "  1.02511444e+004  6.09600000e+000  0.00000000e+000              nan\n",
      "  7.00000000e-001  3.88335701e+000  5.30970272e+000  3.08000000e-001\n",
      "  0.00000000e+000              nan  1.14400000e+000  3.80886280e+241\n",
      "              nan  4.12000000e-001  0.00000000e+000              nan\n",
      "  2.28000000e-001  1.00000000e+000  1.00000000e+000  1.93200000e+000\n",
      "  5.53367793e+000  6.48717776e+000  2.84000000e-001  1.00000000e+000\n",
      "  1.00000000e+000  1.93200000e+000  1.00000000e+000  1.00000000e+000\n",
      "  1.93200000e+000  1.00000000e+000  1.00000000e+000  1.93200000e+000\n",
      "  1.00000000e+000  1.00000000e+000  1.93200000e+000  1.00000000e+000\n",
      "  1.00000000e+000  1.93200000e+000  1.00000000e+000  1.00000000e+000\n",
      "  1.93200000e+000  1.00000000e+000  1.00000000e+000  1.93200000e+000\n",
      "  1.00000000e+000  1.00000000e+000  1.93200000e+000  1.25829557e+000\n",
      "  1.35922573e+000  4.84000000e-001  3.69591820e+000  4.82768459e+000\n",
      "  3.00000000e-001  1.00000000e+000  1.00000000e+000  1.93200000e+000\n",
      "  1.00000000e+000  1.00000000e+000  1.93200000e+000  1.00000000e+000\n",
      "  1.00000000e+000  1.60400000e+000  1.00000000e+000  1.00000000e+000\n",
      "  1.60400000e+000  1.00000000e+000  1.00000000e+000  1.60400000e+000\n",
      "  1.00000000e+000  1.00000000e+000  1.60400000e+000  1.00000000e+000\n",
      "  1.00000000e+000  1.60400000e+000  1.00000000e+000  1.00000000e+000\n",
      "  1.60400000e+000  1.00000000e+000  1.00000000e+000  1.60400000e+000\n",
      "  3.84016416e+000  4.63235922e+000  3.24000000e-001  1.00000000e+000\n",
      "  1.00000000e+000  1.60400000e+000  1.00000000e+000  1.00000000e+000\n",
      "  1.60400000e+000  1.00000000e+000  1.00000000e+000  1.60400000e+000\n",
      "  1.00000000e+000  1.00000000e+000  1.60400000e+000  1.00000000e+000\n",
      "  1.00000000e+000  1.60400000e+000  1.00000000e+000  1.00000000e+000\n",
      "  1.60400000e+000  1.00000000e+000  1.00000000e+000  1.60400000e+000\n",
      "  1.00000000e+000  1.00000001e+000  1.58800000e+000  1.00000000e+000\n",
      "  1.00000001e+000  1.58800000e+000  1.00000000e+000  1.00000001e+000\n",
      "  1.58800000e+000  1.00000000e+000  1.00000001e+000  1.58800000e+000\n",
      "  1.00000000e+000  1.00000001e+000  1.58800000e+000  1.00000000e+000\n",
      "  1.00000001e+000  1.58800000e+000  1.00000000e+000  1.00000001e+000\n",
      "  1.58800000e+000  1.00000000e+000  1.00000001e+000  1.58800000e+000\n",
      "  1.00000000e+000  1.00000001e+000  1.58800000e+000  1.00000000e+000\n",
      "  1.00000001e+000  1.58800000e+000  1.00000000e+000  1.00000001e+000\n",
      "  1.58800000e+000  1.00000000e+000  1.00000001e+000  1.58800000e+000\n",
      "  6.71880857e+000  6.71895109e+000  1.54080000e+001  1.00000000e+000\n",
      "  1.00000001e+000  1.58800000e+000]\n"
     ]
    }
   ],
   "source": [
    "faasSimulator = faas.faas_Model()\n",
    "\n",
    "## repeating last fratio for short rows\n",
    "def simulator(th, seed, simulator_args, batch):\n",
    "    \n",
    "    eps_prior = simulator_args[0]\n",
    "    eps = eps_prior.draw()\n",
    "    #eps.index = ['epsilon' + str(i) for i in np.arange(0,94)]\n",
    "    #eps = [0] * 94\n",
    "    \n",
    "    \n",
    "    return faasSimulator.simulation(np.concatenate([th, eps]), seed)\n",
    "\n",
    "simulator_args = [epsilon_prior]\n",
    "theta0 = faasSimulator.theta0\n",
    "\n",
    "theta_f = [8.886491e+00,  7.924279e+00,\n",
    "   1.050515e+01,  7.397940e+00, -3.682371e+00, -4.509306e+00, -6.162727e+00,\n",
    "  -6.585027e+00,  1.100000e-03, -3.900000e-01]\n",
    "\n",
    "th = [9.91142303e+00,  9.99069025e+00,  8.02619461e+00,  7.84794110e+00,\n",
    " -7.00810822e+00, -3.99945402e+00, -5.60403475e+00, -3.25229427e+00,\n",
    "  8.28864590e-04, -5.00703921e-01]\n",
    "print(simulator(th, 0, simulator_args, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta_fiducial = np.array([8.886491e+00,  7.924279e+00,\n",
    "#   1.050515e+01,  7.397940e+00, -3.682371e+00, -4.509306e+00, -6.162727e+00,\n",
    "#  -6.585027e+00,  1.100000e-03, -3.900000e-01])\n",
    "# eta_fiducial = np.array(np.load('epsfid.npy'))\n",
    "\n",
    "# Cinv = faasSimulator.Cinv\n",
    "# #np.save('Finv.npy', Finv) # save Finv\n",
    "# mu = np.load('mu.npy') # save mu\n",
    "# #np.save('Cinv.npy', Cinv) # save Cinv\n",
    "# dmudt = np.load('dmudt.npy') # save dmudt\n",
    "\n",
    "\n",
    "# Compressor = score.Gaussian(len(faasSimulator.data()[0,:]), np.concatenate([theta_fiducial, eta_fiducial]), \n",
    "#                             mu = mu, Cinv = Cinv, dmudt = dmudt)\n",
    "\n",
    "# Compressor.compute_fisher()\n",
    "# Finv = Compressor.Finv[0:10,0:10]\n",
    "\n",
    "# nuisance_indices = np.arange(10,104)\n",
    "\n",
    "# def compressor(d, compressor_args):\n",
    "#     nuisances_indices = compressor_args[0]\n",
    "#     return Compressor.projected_scoreMLE(d, nuisance_indices)\n",
    "# compressor_args = [nuisance_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Set up the compressor\n",
    "This must have the signature `compressor(data, args)` -> `np.array([n_summaries])`\n",
    "In this case we are going to do _nuisance hardened_ Gaussian score compression $$\\bar{\\mathbf{t}}_\\theta = \\mathbf{t}_\\theta - \\mathbf{F}_{\\theta\\eta}\\mathbf{F}^{-1}_{\\eta\\eta}\\mathbf{t}_\\eta$$ where $$\\mathbf{t}_{(\\theta, \\eta)} = \\nabla_{(\\theta, \\eta)}^T\\boldsymbol\\mu_*\\mathbf{C}^{-1}(\\mathbf{d}-\\boldsymbol\\mu_*)$$\n",
    "We'll use the class `score.Gaussian`. For this we'll need some fiducial parameters, the mean its derivative at the fiducial parameters, the inverse covariance, and the inverse Fisher matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(282, 282)\n",
      "(104, 282)\n"
     ]
    }
   ],
   "source": [
    "theta_fiducial = np.array([8.886491e+00,  7.924279e+00,\n",
    "  1.050515e+01,  7.397940e+00, -3.682371e+00, -4.509306e+00, -6.162727e+00,\n",
    " -6.585027e+00,  1.100000e-03, -3.900000e-01])\n",
    "eta_fiducial = [0.1] * 94\n",
    "#print(eta_fiducial)\n",
    "mu = faasSimulator.simulation(np.concatenate([theta_fiducial, eta_fiducial]), seed)\n",
    "Cinv = faasSimulator.Cinv\n",
    "print(Cinv.shape)\n",
    "\n",
    "h = np.array(abs(np.concatenate([theta_fiducial, eta_fiducial])))*0.01\n",
    "dmudt = faasSimulator.dmudt(np.concatenate([theta_fiducial, eta_fiducial]), h)\n",
    "print(dmudt.shape)\n",
    "Compressor = score.Gaussian(len(faasSimulator.data()[0,:]), np.concatenate([theta_fiducial, eta_fiducial]), \n",
    "                            mu = mu, Cinv = Cinv, dmudt = dmudt)\n",
    "\n",
    "Compressor.compute_fisher()\n",
    "Finv = Compressor.Finv[0:10,0:10]\n",
    "\n",
    "nuisance_indices = np.arange(10,104)\n",
    "\n",
    "def compressor(d, compressor_args):\n",
    "    nuisances_indices = compressor_args[0]\n",
    "    return Compressor.projected_scoreMLE(d, nuisance_indices)\n",
    "compressor_args = [nuisance_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load in the compressed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.84693319e+00  7.87193946e+00  1.04668244e+01  7.60554193e+00\n",
      " -3.66810304e+00 -4.46340453e+00 -6.15641698e+00 -6.59143228e+00\n",
      "  1.09671346e-03 -3.88028524e-01]\n"
     ]
    }
   ],
   "source": [
    "compressed_data = compressor(faasSimulator.data_comp(), compressor_args)\n",
    "print(compressed_data)\n",
    "n_data = len(compressed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save FINV, only worth doing once, make sure to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('Finv.npy', Finv) # save Finv\n",
    "# np.save('mu.npy', mu) # save mu\n",
    "# #np.save('Cinv.npy', Cinv) # save Cinv\n",
    "# np.save('dmudt.npy', dmudt) # save dmudt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = faasSimulator.data()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Define ensemble of NDEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NDEs = [ndes.ConditionalMaskedAutoregressiveFlow(n_parameters=10, n_data=n_data, n_hiddens=[50,50], n_mades=8, act_fun=tf.tanh, index=0),\n",
    "        ndes.MixtureDensityNetwork(n_parameters=10, n_data=n_data, n_components=1, n_hidden=[30,30], activations=[tf.tanh, tf.tanh], index=1),\n",
    "        ndes.MixtureDensityNetwork(n_parameters=10, n_data=n_data, n_components=2, n_hidden=[30,30], activations=[tf.tanh, tf.tanh], index=2),\n",
    "        ndes.MixtureDensityNetwork(n_parameters=10, n_data=n_data, n_components=3, n_hidden=[30,30], activations=[tf.tanh, tf.tanh], index=3),\n",
    "        ndes.MixtureDensityNetwork(n_parameters=10, n_data=n_data, n_components=4, n_hidden=[30,30], activations=[tf.tanh, tf.tanh], index=4),\n",
    "        ndes.MixtureDensityNetwork(n_parameters=10, n_data=n_data, n_components=5, n_hidden=[30,30], activations=[tf.tanh, tf.tanh], index=5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Create DELFI object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DelfiEnsemble = delfi.Delfi(compressed_data, prior, NDEs, Finv = None, theta_fiducial = theta_fiducial,\n",
    "                       param_limits = [np.concatenate((lower, [(0.0011-(0.0011*0.8)**2),(-0.39-(0.39*0.8)**2)])), np.concatenate((upper, [(0.0011+(0.0011*0.8)**2),(-0.39+(0.39*0.8)**2)]))],\n",
    "                       param_names = ['logKonTN', 'logKonTC', 'logKonRN', 'logKonRC', 'logKDTN', 'logKDTC', 'logKDRN', 'logKDRC', 'malpha', 'alpha0'],\n",
    "                       results_dir = \"results/\",input_normalization = None, restore = True, save = False, nwalkers = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DelfiEnsemble = delfi.Delfi(compressed_data, prior, NDEs,\n",
    "#                        param_names = ['logKonTN', 'logKonTC', 'logKonRN', 'logKonRC', 'logKDTN', 'logKDTC', 'logKDRN', 'logKDRC', 'malpha', 'alpha0'],\n",
    "#                        results_dir = \"results_batch_whole_comp/\", restore = False, save = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fisher pre-training to initialize the NDEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DelfiEnsemble.fisher_pretraining(plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sequential Neural Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_initial = 200\n",
    "n_batch = 200\n",
    "n_populations = 39\n",
    "\n",
    "DelfiEnsemble.sequential_training(simulator, compressor, n_initial, n_batch, n_populations, patience=50., save_intermediate_posteriors=False, simulator_args = simulator_args, compressor_args = compressor_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample the learned posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/anaconda3/envs/thesis/lib/python3.6/site-packages/emcee/ensemble.py:335: RuntimeWarning: invalid value encountered in subtract\n",
      "  lnpdiff = (self.dim - 1.) * np.log(zz) + newlnprob - lnprob0\n",
      "/home/thomas/anaconda3/envs/thesis/lib/python3.6/site-packages/emcee/ensemble.py:336: RuntimeWarning: invalid value encountered in greater\n",
      "  accept = (lnpdiff > np.log(self._random.rand(len(lnpdiff))))\n"
     ]
    }
   ],
   "source": [
    "from emcee.autocorr import integrated_time\n",
    "#from emcee.moves import StretchMove\n",
    "\n",
    "def emcee_sample(log_likelihood=None, x0=None, burn_in_chain=10, main_chain=10, nwalkers= 2000):\n",
    "\n",
    "        # Set the log likelihood (default to the posterior if none given)\n",
    "        if log_likelihood is None:\n",
    "            log_likelihood = lambda x: DelfiEnsemble.log_posterior_stacked(x, DelfiEnsemble.data)[0]\n",
    "\n",
    "        # Set up default x0\n",
    "        if x0 is None:\n",
    "            #x0 = emcee.utils.sample_ball(theta_fiducial, [0.01]*8 + [0.001] + [0.01], nwalkers)\n",
    "            x0 = [DelfiEnsemble.posterior_samples[-i,:] for i in range(nwalkers)]\n",
    "\n",
    "        # Set up the sampler\n",
    "        sampler = emcee.EnsembleSampler(nwalkers, 10, log_likelihood)\n",
    "\n",
    "        # Burn-in chain\n",
    "        pos, prob, state = sampler.run_mcmc(x0, burn_in_chain)\n",
    "        sampler.reset()\n",
    "\n",
    "        sampler.run_mcmc(pos, main_chain)\n",
    "        #print(sampler.acceptance_fraction)\n",
    "        return sampler.flatchain\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "posterior_samples = emcee_sample(burn_in_chain=1000, main_chain=3000)\n",
    "\n",
    "# acls = []\n",
    "# for samps in posterior_samples:\n",
    "#     acls.append(integrated_time(samps))\n",
    "#     posterior_samples = posterior_samples[0:-1:int(np.max(acls)),:]\n",
    "\n",
    "    \n",
    "print(posterior_samples)\n",
    "post = np.unique(posterior_samples, axis=0)\n",
    "np.save('pst_samples.npy', post) # save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alright let's plot it!\n",
    "Feed it a list of `(n_samples, n_parameters)` arrays for making a triangle plot; in this case let's just plot the posterior samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "posterior_samples = np.load('pst_samples_whole_comp_fisher_pre.npy')\n",
    "pst = np.unique(posterior_samples, axis=0)\n",
    "print(pst.shape)\n",
    "print(pst)\n",
    "print(posterior_samples.shape)\n",
    "triangle_plot(samples=[post], savefig=True, filename='whole_comp_pre.pdf')\n",
    "\n",
    "# param_names = ['logKonTN', 'logKonTC', 'logKonRN', 'logKonRC', 'logKDTN', 'logKDTC', 'logKDRN', 'logKDRC', 'malpha', 'alpha0']\n",
    "# from IPython.display import display, Math\n",
    "# params_med = []\n",
    "# params_up = []\n",
    "# params_low = []\n",
    "# for i in range(10):\n",
    "#     mcmc = np.percentile(posterior_samples[:, i], [16, 50, 84])\n",
    "#     q = np.diff(mcmc)\n",
    "#     txt = \"\\mathrm{{{3}}} = {0:.4f}_{{-{1:.4f}}}^{{{2:.4f}}}\"\n",
    "#     txt = txt.format(mcmc[1], q[0], q[1], param_names[i])\n",
    "#     params_low.append(mcmc[1] - q[0])\n",
    "#     params_med.append(mcmc[1])\n",
    "#     params_up.append(mcmc[1] + q[1])\n",
    "#     print(txt)\n",
    "\n",
    "\n",
    "# plt.show()\n",
    "# print(params_med)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot learned log-likelihood vs squared error (proportional to Gaussian Likelihood)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post = np.load('pst_samples_whole_comp_fisher.npy')\n",
    "# post = np.unique(post, axis=0)\n",
    "# eps = [0]*94\n",
    "# ll = lambda x: np.sum(np.sum((faasSimulator.data() - faasSimulator.forward(np.concatenate((x,eps)), seed))**2))\n",
    "\n",
    "# ll_post = lambda x: DelfiEnsemble.log_likelihood_stacked(x, DelfiEnsemble.data)[0]\n",
    "\n",
    "# # # pt_ll = [ll(i) for i in post]\n",
    "# pt_ll_post = [ll_post(i) for i in post]\n",
    "# #print(post.shape)\n",
    "x = np.loadtxt(open('def.csv', \"rb\"), delimiter=',').T\n",
    "\n",
    "plt.scatter(x[0], x[1])\n",
    "plt.plot(np.unique(x[0]), np.poly1d(np.polyfit(x[0], x[1], 1))(np.unique(x[0])), color='red')\n",
    "plt.xlabel(\"NDE log likelihood\")\n",
    "plt.ylabel(\"Squared Error\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('postvssquared_500.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
