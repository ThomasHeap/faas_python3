{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import simulator as faas\n",
    "\n",
    "\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up priors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import delfi.distribution as dd\n",
    "\n",
    "upper = np.array([12,  10, 12,  10, -3, -4, -4,-4] + [0.1,0])\n",
    "lower = np.array([4,  2, 4, 2, -10, -10, -10, -12] + [-0.1,-0.5])\n",
    "\n",
    "prior_mean = np.array([0]*8 + [1.1e-03, -3.9e-01])\n",
    "prior_cov = np.diag(np.array([10]*8+[(0.0011*0.2)**2, (0.39*0.2)**2]))\n",
    "\n",
    "prior = dd.Uniform(lower= lower, upper=upper, seed=seed)\n",
    "\n",
    "epsilon_mean = np.array([0]*94)\n",
    "epsilon_cov = np.diag(np.array([0.5] * 94))\n",
    "epsilon_prior = dd.Gaussian(m=epsilon_mean, S=epsilon_cov, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "faasSimulator = faas.faas_Model()\n",
    "\n",
    "## repeating last fratio for short rows\n",
    "def simulator(th, seed, simulator_args, batch):\n",
    "    \n",
    "    eps_prior = simulator_args[0]\n",
    "    eps = eps_prior.gen()[0]\n",
    "    #eps.index = ['epsilon' + str(i) for i in np.arange(0,94)]\n",
    "    #eps = [0] * 94\n",
    "    \n",
    "    if len(th) < 104:\n",
    "        return faasSimulator.forward(np.concatenate([th, eps]), seed)\n",
    "    else:\n",
    "        return faasSimulator.forward(th, seed)\n",
    "\n",
    "simulator_args = [epsilon_prior]\n",
    "theta0 = faasSimulator.theta0\n",
    "\n",
    "theta_f = [8.886491e+00,  7.924279e+00,\n",
    "   1.050515e+01,  7.397940e+00, -3.682371e+00, -4.509306e+00, -6.162727e+00,\n",
    "  -6.585027e+00,  1.100000e-03, -3.900000e-01]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delfi.simulator.BaseSimulator import BaseSimulator\n",
    "\n",
    "class Faas(BaseSimulator):\n",
    "    def __init__(self, batch=0, simulator_args = simulator_args, seed=None):\n",
    "        \"\"\"Faas simulator\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        seed : int or None\n",
    "            If set, randomness across runs is disabled\n",
    "        \"\"\"\n",
    "        dim_param = 104\n",
    "\n",
    "        super().__init__(dim_param=dim_param, seed=seed)\n",
    "        self.batch = batch\n",
    "        self.simulator_args = simulator_args\n",
    "        self.seed = seed\n",
    "        self.FaasSimulator = simulator\n",
    "        self.time = np.genfromtxt('data/time_points.csv', delimiter=',')\n",
    "\n",
    "    def gen_single(self, params):\n",
    "        \"\"\"Forward model for simulator for single parameter set\n",
    "\n",
    "        Parametersnp.nanstd(stats, axis=0)\n",
    "        ----------\n",
    "        params : list or np.array, 1d of length dim_param\n",
    "            Parameter vector\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict : dictionary with data\n",
    "            The dictionary must contain a key data that contains the results of\n",
    "            the forward run. Additional entries can be present.\n",
    "        \"\"\"\n",
    "        params = np.asarray(params)\n",
    "\n",
    "        assert params.ndim == 1, 'params.ndim must be 1'\n",
    "\n",
    "        hh_seed = self.seed\n",
    "\n",
    "        states = self.FaasSimulator(th = params, seed = seed, simulator_args = self.simulator_args, batch = self.batch)\n",
    "        if np.isnan(states.flatten()).any() or np.isinf(states.flatten()).any():\n",
    "            states = np.random.randn(94,259)\n",
    "                #return d.flatten()\n",
    "        \n",
    "        return {'data': states[:,::3], 'time': self.time}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delfi.summarystats.Score_Sum_Stats import Score_MLE_Projected\n",
    "sim = Faas(simulator_args=simulator_args)\n",
    "ndata = len(sim.gen_single(theta_f)['data'].flatten())\n",
    "nuisance_indices = np.arange(10,104)\n",
    "Score = Score_MLE_Projected(ndata = ndata, theta_fiducial=theta_f + [0.1]*94, nuisances=nuisance_indices, seed=0, n_summary=10)\n",
    "Score.compute_mean_covariance(sim.gen_single, 50, simulator_args=simulator_args)\n",
    "Score.compute_derivatives(sim.gen_single, 50, [0.01]*10 + [0.5]*94, simulator_args=simulator_args)\n",
    "print(Score.mu.shape)\n",
    "print(Score.Cinv.shape)\n",
    "print(Score.dmudt.shape)\n",
    "Score.compute_fisher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('mu.npy', Score.mu)\n",
    "np.save('Cinv.npy', Score.Cinv)\n",
    "np.save('F.npy', Score.F)\n",
    "np.save('dmudt.npy', Score.dmudt)\n",
    "#np.save('dCdt.npy' , Score.dCdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27\n",
      "  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45\n",
      "  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63\n",
      "  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103]\n",
      "(8178,)\n",
      "(8178, 8178)\n",
      "(104, 8178)\n"
     ]
    }
   ],
   "source": [
    "from delfi.summarystats.Score_Sum_Stats import Score_MLE_Projected\n",
    "\n",
    "mu = np.load('mu.npy')\n",
    "Cinv = np.load('Cinv.npy', allow_pickle=True)\n",
    "#Cinv = np.diag([10]*8178)\n",
    "F = np.load('F.npy', allow_pickle=True)\n",
    "dmudt = np.load('dmudt.npy', allow_pickle=True)\n",
    "dCdt = np.load('dCdt.npy', allow_pickle=True)\n",
    "\n",
    "sim = Faas(simulator_args=simulator_args)\n",
    "ndata = len(sim.gen_single(theta_f)['data'].flatten())\n",
    "nuisance_indices = np.arange(10,104)\n",
    "print(nuisance_indices)\n",
    "#print((theta_f + [0.1]*94)[np.delete(np.arange(len(theta_f + [0]*94)), nuisance_indices)])\n",
    "Score = Score_MLE_Projected(ndata = ndata, theta_fiducial=np.asarray(theta_f + [0.1]*94), nuisances=nuisance_indices, seed=0, mu=mu, Cinv=Cinv, dmudt=dmudt,F=F, n_summary = 10)\n",
    "#Score.compute_mean_covariance(sim.gen_single, 10, simulator_args=simulator_args)\n",
    "#Score.compute_derivatives(sim.gen_single, 10, [0.01]*10 + [0.5]*94, simulator_args=simulator_args)\n",
    "print(Score.mu.shape)\n",
    "print(Score.Cinv.shape)\n",
    "print(Score.dmudt.shape)\n",
    "#print(Score.F.shape) \n",
    "#Score.compute_fisher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delfi.summarystats.BaseSummaryStats import BaseSummaryStats\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.signal import find_peaks, peak_widths\n",
    "\n",
    "class FaasStats(BaseSummaryStats):\n",
    "    \"\"\"Moment based SummaryStats class for the faas model\n",
    "\n",
    "    Calculates summary statistics\n",
    "    \"\"\"\n",
    "    def __init__(self, seed=None):\n",
    "        \"\"\"See SummaryStats.py for docstring\"\"\"\n",
    "        super(FaasStats, self).__init__(seed=seed)\n",
    "        self.time = np.genfromtxt('data/time_points.csv', delimiter=',')\n",
    "    \n",
    "    def compressor(self, d, t):\n",
    "            comp_d = []\n",
    "\n",
    "#             for i in d:\n",
    "#                 #mean of final ten entries\n",
    "#                 final = np.mean(i[-10:])\n",
    "#                 #median of 3 highest points\n",
    "#                 peak = np.max(i)\n",
    "#                 #time to peak\n",
    "#                 time_peak = t[np.argmax(i)]\n",
    "#                 #sd = np.std(i[-10:])\n",
    "#                 #time to final\n",
    "#                 #time_final = np.argmax(np.logical_and((i[time_peak:] >= final - sd),(i[time_peak:] <= final + sd)) == True) + time_peak\n",
    "#                 diff_peak_final = (final - peak)/peak * 100\n",
    "#                 first = np.mean(i[:5])\n",
    "#                 diff_peak_first = first - peak\n",
    "#                 diff_first_final = first - final\n",
    "#                 mid = i[len(i)//2]\n",
    "#                 diff_first_mid = first - mid\n",
    "#                 diff_final_mid = final - mid\n",
    "#                 diff_peak_mid = peak - mid\n",
    "#                 if time_peak > 259:\n",
    "#                     time_peak = np.random.uniform(0, 259)\n",
    "#                 if diff_peak_final > 25:\n",
    "#                     diff_peak_final = np.random.uniform(0.1, 0.2)\n",
    "                \n",
    "#                 min_slope = np.diff(i).min()\n",
    "#                 max_slope = np.diff(i[10:]).max()\n",
    "                \n",
    "#                 max_slope_index = t[np.argmax(np.diff(i[10:])) + 10] \n",
    "#                 min_slope_index = t[np.argmin(np.diff(i[10:]))] \n",
    "                \n",
    "#                 #mean slope for first 10, 20, and then the remaining trace\n",
    "#                 mean_10 = np.mean(np.diff(i)[:10])\n",
    "#                 mean_30 = np.mean(np.diff(i)[10:30])\n",
    "#                 mean_rest = np.mean(np.diff(i)[30:])\n",
    "                \n",
    "#                 #moments\n",
    "#                 #mom_1 = stats.moment(i, 1, nan_policy = 'omit')\n",
    "#                 mom_2 = stats.moment(i, 2, nan_policy = 'omit')\n",
    "#                 mom_3 = stats.moment(i, 3, nan_policy = 'omit')\n",
    "#                 mom_4 = stats.moment(i, 4, nan_policy = 'omit')\n",
    "#                 mom_5 = stats.moment(i, 5, nan_policy = 'omit')\n",
    "                \n",
    "#                 #moments of differenced trace\n",
    "#                 mom_diff_1 = stats.moment(np.diff(i), 1, nan_policy = 'omit')\n",
    "#                 mom_diff_2 = stats.moment(np.diff(i), 2, nan_policy = 'omit')\n",
    "#                 mom_diff_3 = stats.moment(np.diff(i), 3, nan_policy = 'omit')\n",
    "#                 mom_diff_4 = stats.moment(np.diff(i), 4, nan_policy = 'omit')\n",
    "#                 mom_diff_5 = stats.moment(np.diff(i), 5, nan_policy = 'omit')\n",
    "                \n",
    "#                 # peaks\n",
    "#                 #peaks, _ = find_peaks(i)\n",
    "#                 #peaks_widths = peak_widths(i, peaks)[0]\n",
    "                \n",
    "#                 #comp_d.append([time_peak, min_slope, max_slope, diff_peak_final, diff_peak_first, max_slope_index, \n",
    "#                 #               min_slope_index, mean_10, mean_30, mean_rest, diff_first_mid, diff_final_mid, \n",
    "#                 #               diff_peak_mid, mom_2, mom_3, mom_4, mom_5,\n",
    "#                 #               mom_diff_1, mom_diff_2, mom_diff_3, mom_diff_4, mom_diff_5])\n",
    "#                 #               #peaks, peaks_widths])\n",
    "\n",
    "\n",
    "            #out = np.asarray(comp_d).flatten()\n",
    "            #out = comp_d\n",
    "            out = d.flatten()\n",
    "            if np.isnan(out).any() or np.isinf(out).any():\n",
    "                return np.random.randn(out.shape[0])**2\n",
    "                #return d.flatten()\n",
    "\n",
    "            #return out + np.random.rand(6*len(d))\n",
    "            return out\n",
    "    \n",
    "    def calc(self, repetition_list):\n",
    "        \"\"\"Calculate summary statistics\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        repetition_list : list of dictionaries, one per repetition\n",
    "            data list, returned by `gen` method of Simulator instance\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array, 2d with n_reps x n_summary\n",
    "        \"\"\"\n",
    "        stats = []\n",
    "        for r in range(len(repetition_list)):\n",
    "            x = repetition_list[r]\n",
    "\n",
    "            N = x['data']\n",
    "            t = self.time\n",
    "\n",
    "            # concatenation of summary statistics\n",
    "            sum_stats_vec = self.compressor(N, t)\n",
    "            #sum_stats_vec = sum_stats_vec[0:self.n_summary]\n",
    "\n",
    "            stats.append(sum_stats_vec)\n",
    "\n",
    "        return np.asarray(stats)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import delfi.generator as dg\n",
    "\n",
    "\n",
    "m = Faas(seed=0)\n",
    "s = Score\n",
    "g = dg.Default(model=m, prior=prior, summary=s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94, 259)\n",
      "[[ 1.53874     1.52949     1.52024    ...  1.22611     1.43572667\n",
      "   1.64534333]\n",
      " [ 1.85496     1.85207     1.84919    ...  1.3128      1.56277\n",
      "   1.81274   ]\n",
      " [ 2.06271     2.07622     2.08974    ...  1.47581     1.78714\n",
      "   2.09847   ]\n",
      " ...\n",
      " [15.2519     15.5032     15.6159     ... 17.8333     17.3501\n",
      "  17.479     ]\n",
      " [16.473      16.802      16.9616     ... 21.1703     20.9748\n",
      "  21.382     ]\n",
      " [15.7665     16.0305     16.1803     ... 21.2085     20.9053\n",
      "  20.6735    ]]\n"
     ]
    }
   ],
   "source": [
    "labels_params = ['logKonTN', 'logKonTC', 'logKonRN', 'logKonRC', 'logKDTN', 'logKDTC', 'logKDRN', 'logKDRC', 'malpha', 'alpha0'] + ['eps' + str(i) for i in range(93)]\n",
    "\n",
    "\n",
    "data = np.genfromtxt('data/timecourse.csv', delimiter=',').T\n",
    "print(data.shape)\n",
    "mask = np.isnan(data)\n",
    "data[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), data[~mask])\n",
    "\n",
    "print(data)\n",
    "\n",
    "data = {'data': data[:,::3], 'time': np.genfromtxt('data/time_points.csv', delimiter=',')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true parameters and respective labels\n",
    "true_params = np.array([8.886491e+00,  7.924279e+00, 1.050515e+01,  7.397940e+00, \n",
    "                        -3.682371e+00, -4.509306e+00, -6.162727e+00, -6.585027e+00,  \n",
    "                        1.100000e-03, -3.900000e-01])       \n",
    "labels_params = ['logKonTN', 'logKonTC', 'logKonRN', 'logKonRC', 'logKDTN', 'logKDTC', 'logKDRN', 'logKDRC', 'malpha', 'alpha0']\n",
    "\n",
    "\n",
    "\n",
    "#true_params = np.array([8.886491e+00,  7.924279e+00,\n",
    "#   1.050515e+01,  7.397940e+00, -3.682371e+00])       \n",
    "#labels_params = ['logKonTN', 'logKonTC', 'logKonRN', 'logKonRC', 'logKDTN']# 'logKDRN', 'logKDRC', 'malpha', 'alpha0']\n",
    "\n",
    "\n",
    "# observed data: simulation given true parameters\n",
    "obs = m.gen_single(true_params)\n",
    "print(obs['data'].shape)\n",
    "print(obs['data'].flatten().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(7,5))\n",
    "ax = plt.subplot()\n",
    "for i in data['data']:\n",
    "    plt.plot(data['time'],i)\n",
    "plt.ylabel('voltage (mV)')\n",
    "plt.title('observed data')\n",
    "ax.set_xticks([])\n",
    "\n",
    "for i in obs['data']:\n",
    "    plt.plot(obs['time'],i)\n",
    "plt.ylabel('voltage (mV)')\n",
    "plt.title('observed data')\n",
    "ax.set_xticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.96085048e+00  6.93103781e+00  7.75887669e+00  7.21633548e+00\n",
      "  -6.52755286e+00 -5.04618909e+00 -2.88295462e+00 -6.41258002e+00\n",
      "   1.11861603e-03 -4.34634373e-01]]\n",
      "(1, 10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "obs_stats = s.calc([data])\n",
    "print(obs_stats)\n",
    "print(obs_stats.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_inf = 20\n",
    "\n",
    "pilot_samples = 20\n",
    "\n",
    "# training schedule\n",
    "n_train = 500\n",
    "n_rounds = 5\n",
    "\n",
    "# fitting setup\n",
    "minibatch = 100\n",
    "epochs = 100\n",
    "val_frac = 0.05\n",
    "\n",
    "# network setup\n",
    "n_hiddens = [50]*5\n",
    "\n",
    "# convenience\n",
    "prior_norm = True\n",
    "\n",
    "# MAF parameters\n",
    "density = 'maf'\n",
    "n_mades = 5       # number of MADES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6b4a752d7d41f4a6b576aab59a91c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c8c6bb2fbbe4031b8e50c936bf2ed12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b0de2d4e904f7aa628a416ace47bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=480.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c109cfa30f47e7a9227c3a5bf62553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=480.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import delfi.inference as infer\n",
    " \n",
    "# inference object\n",
    "res = infer.SNPEC(g,\n",
    "                obs=obs_stats,\n",
    "                n_hiddens=n_hiddens,\n",
    "                seed=seed_inf,\n",
    "                pilot_samples=pilot_samples,\n",
    "                n_mades=n_mades,\n",
    "                prior_norm=prior_norm,\n",
    "                density=density, verbose=True)\n",
    "\n",
    "# train\n",
    "log, _, posterior = res.run(\n",
    "                    n_train=n_train,\n",
    "                    n_rounds=n_rounds,\n",
    "                    minibatch=minibatch,\n",
    "                    epochs=epochs,\n",
    "                    silent_fail=False,\n",
    "                    proposal='prior',\n",
    "                    val_frac=val_frac,\n",
    "                    verbose=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.plot(log[0]['loss'],lw=2)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delfi.utils.viz import samples_nd\n",
    "\n",
    "#lower= [4,2,4,2], upper=[12,10,12,10]\n",
    "\n",
    "prior_min = lower\n",
    "prior_max = upper\n",
    "prior_lims = np.concatenate((prior_min.reshape(-1,1),prior_max.reshape(-1,1)),axis=1)\n",
    "\n",
    "posterior_samples = posterior[0].gen(10000)\n",
    "\n",
    "###################\n",
    "# colors\n",
    "hex2rgb = lambda h: tuple(int(h[i:i+2], 16) for i in (0, 2, 4))\n",
    "\n",
    "# RGB colors in [0, 255]\n",
    "col = {}\n",
    "col['GT']      = hex2rgb('30C05D')\n",
    "col['SNPE']    = hex2rgb('2E7FE8')\n",
    "col['SAMPLE1'] = hex2rgb('8D62BC')\n",
    "col['SAMPLE2'] = hex2rgb('AF99EF')\n",
    "\n",
    "# convert to RGB colors in [0, 1]\n",
    "for k, v in col.items():\n",
    "    col[k] = tuple([i/255 for i in v])\n",
    "\n",
    "###################\n",
    "# posterior\n",
    "fig, axes = samples_nd(posterior_samples,\n",
    "                       limits=prior_lims,\n",
    "                       ticks=prior_lims,\n",
    "                       labels=labels_params,\n",
    "                       fig_size=(5,5),\n",
    "                       diag='kde',\n",
    "                       upper='kde',\n",
    "                       hist_diag={'bins': 50},\n",
    "                       hist_offdiag={'bins': 50},\n",
    "                       kde_diag={'bins': 50, 'color': col['SNPE']},\n",
    "                       kde_offdiag={'bins': 50},\n",
    "                       points=[true_params],\n",
    "                       points_offdiag={'markersize': 5},\n",
    "                       points_colors=[col['GT']],\n",
    "                       title='');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "inferred_params = np.median(posterior_samples.reshape(10000,10), axis=0)\n",
    "print(inferred_params)\n",
    "print(true_params)\n",
    "\n",
    "data = m.gen_single(inferred_params)\n",
    "#print(data['data'][0])\n",
    "#print(obs['data'][0])\n",
    "print(s.calc([data]))\n",
    "print(s.calc([obs]))\n",
    "print(mean_squared_error(s.calc([data]),s.calc([obs])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(7,5))\n",
    "ax = plt.subplot()\n",
    "for i in data['data']:\n",
    "    plt.plot(data['time'],i)\n",
    "plt.ylabel('voltage (mV)')\n",
    "plt.title('observed data')\n",
    "ax.set_xticks([])\n",
    "\n",
    "for i in obs['data']:\n",
    "    plt.plot(obs['time'],i)\n",
    "plt.ylabel('voltage (mV)')\n",
    "plt.title('observed data')\n",
    "ax.set_xticks([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
